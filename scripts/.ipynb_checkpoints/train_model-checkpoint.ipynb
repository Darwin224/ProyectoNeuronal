{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c65a7c2-0e9a-4587-a9a2-32c59f28f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from neural_network import RedNeuronal\n",
    "from image_processor import ImageProcessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a41ca151-41eb-480c-850a-886f8fde2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"=== Entrenamiento de Red Neuronal para Reconocimiento de Imágenes ===\\n\")\n",
    "    \n",
    "    # Configuración\n",
    "    TARGET_SIZE = (600, 800)\n",
    "    EPOCHS = 100\n",
    "    LEARNING_RATE = 0.01\n",
    "    BATCH_SIZE = 8\n",
    "    \n",
    "    # Inicializar procesador de imágenes\n",
    "    processor = ImageProcessor(target_size=TARGET_SIZE)\n",
    "    \n",
    "    # Verificar existencia del dataset\n",
    "    dataset_path = \"dataset\"\n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(\"❌ No se encontró la carpeta 'dataset'. Asegúrate de que exista y contenga imágenes organizadas por clase.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Cargar y procesar dataset\n",
    "        print(\"📁 Cargando dataset...\")\n",
    "        X, y, class_names = processor.create_dataset_from_folder(dataset_path)\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            print(\"❌ No se encontraron imágenes en el dataset. Verifica que la carpeta contenga imágenes válidas.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"✅ Dataset cargado exitosamente:\")\n",
    "        print(f\"   - {len(X)} imágenes\")\n",
    "        print(f\"   - {len(class_names)} clases: {class_names}\")\n",
    "        print(f\"   - Tamaño de entrada: {X.shape[1]} píxeles\\n\")\n",
    "        \n",
    "        # División de datos\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"📊 División del dataset:\")\n",
    "        print(f\"   - Entrenamiento: {len(X_train)} imágenes\")\n",
    "        print(f\"   - Prueba: {len(X_test)} imágenes\\n\")\n",
    "        \n",
    "        # Arquitectura de la red neuronal\n",
    "        n_classes = len(class_names)\n",
    "        input_size = X.shape[1]  # Número de píxeles\n",
    "        \n",
    "        # Arquitectura compatible con tu RedNeuronal\n",
    "        architecture = [\n",
    "            (input_size, 'input'),      # Capa de entrada (OBLIGATORIA)\n",
    "            (256, 'relu'),              # Capa oculta 1\n",
    "            (128, 'relu'),              # Capa oculta 2\n",
    "            (64, 'relu'),               # Capa oculta 3\n",
    "            (32, 'relu'),               # Capa oculta 4\n",
    "            (n_classes, 'softmax')      # Capa de salida\n",
    "        ]\n",
    "        \n",
    "        print(f\"🧠 Arquitectura de la red neuronal:\")\n",
    "        for i, (neurons, activation) in enumerate(architecture):\n",
    "            if i == 0:\n",
    "                layer_type = \"Entrada\"\n",
    "            elif i == len(architecture) - 1:\n",
    "                layer_type = \"Salida\"\n",
    "            else:\n",
    "                layer_type = f\"Oculta {i}\"\n",
    "            print(f\"   - Capa {layer_type}: {neurons} neuronas ({activation})\")\n",
    "        print()\n",
    "        \n",
    "        # Entrenamiento\n",
    "        print(\"🚀 Iniciando entrenamiento...\")\n",
    "        red = RedNeuronal(architecture)\n",
    "        red.train(\n",
    "            X_train, y_train,\n",
    "            epochs=EPOCHS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\n✅ Entrenamiento completado!\\n\")\n",
    "        \n",
    "        # Evaluación\n",
    "        print(\"📈 Evaluando modelo...\")\n",
    "        train_loss, train_accuracy = red.evaluate(X_train, y_train)\n",
    "        test_loss, test_accuracy = red.evaluate(X_test, y_test)\n",
    "        \n",
    "        print(f\"📊 Resultados finales:\")\n",
    "        print(f\"   - Precisión en entrenamiento: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "        print(f\"   - Precisión en prueba: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "        print(f\"   - Pérdida en entrenamiento: {train_loss:.4f}\")\n",
    "        print(f\"   - Pérdida en prueba: {test_loss:.4f}\\n\")\n",
    "        \n",
    "        # Predicciones de ejemplo\n",
    "        print(\"🔍 Ejemplos de predicciones:\")\n",
    "        predictions = red.predict(X_test[:10])\n",
    "        \n",
    "        for i in range(min(10, len(X_test))):\n",
    "            pred_class_idx = np.argmax(predictions[i])\n",
    "            true_class_idx = np.argmax(y_test[i])\n",
    "            confidence = predictions[i][pred_class_idx]\n",
    "            \n",
    "            pred_class = class_names[pred_class_idx]\n",
    "            true_class = class_names[true_class_idx]\n",
    "            status = \"✅\" if pred_class_idx == true_class_idx else \"❌\"\n",
    "            \n",
    "            print(f\"   {status} Muestra {i+1}: Predicho='{pred_class}' | Real='{true_class}' | Confianza={confidence:.3f}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Guardar modelo\n",
    "        model_filename = \"modelo_reconocimiento_imagenes.json\"\n",
    "        print(f\"💾 Guardando modelo como '{model_filename}'...\")\n",
    "        red.save_model(model_filename)\n",
    "        \n",
    "        # Guardar información del modelo\n",
    "        model_info = {\n",
    "            'class_names': class_names,\n",
    "            'target_size': TARGET_SIZE,\n",
    "            'architecture': architecture,\n",
    "            'training_accuracy': float(train_accuracy),\n",
    "            'test_accuracy': float(test_accuracy),\n",
    "            'input_size': input_size,\n",
    "            'output_size': n_classes\n",
    "        }\n",
    "        \n",
    "        with open(\"modelo_info.json\", \"w\") as f:\n",
    "            json.dump(model_info, f, indent=2)\n",
    "        \n",
    "        print(\"✅ Modelo guardado exitosamente!\\n\")\n",
    "        \n",
    "        # Graficar historial\n",
    "        print(\"📈 Generando gráficas de entrenamiento...\")\n",
    "        plot_training_history(red.training_history)\n",
    "        \n",
    "        print(\"🎉 ¡Proceso completado exitosamente!\")\n",
    "        print(\"Puedes usar el modelo guardado para hacer predicciones en nuevas imágenes.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error durante el entrenamiento: {e}\")\n",
    "        print(\"Por favor, revisa tu dataset y asegúrate de que las imágenes estén correctamente organizadas.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe9eaee6-dd0c-4a3b-b744-a3454b67e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Entrenamiento de Red Neuronal para Reconocimiento de Imágenes ===\n",
      "\n",
      "📁 Cargando dataset...\n",
      "Clases encontradas: ['Darwin', 'No_Darwin']\n",
      "Procesando clase 'Darwin'...\n",
      "  - 20 imágenes procesadas\n",
      "Procesando clase 'No_Darwin'...\n",
      "  - 20 imágenes procesadas\n",
      "Dataset creado: 40 imágenes, 2 clases\n",
      "✅ Dataset cargado exitosamente:\n",
      "   - 40 imágenes\n",
      "   - 2 clases: ['Darwin', 'No_Darwin']\n",
      "   - Tamaño de entrada: 480000 píxeles\n",
      "\n",
      "📊 División del dataset:\n",
      "   - Entrenamiento: 32 imágenes\n",
      "   - Prueba: 8 imágenes\n",
      "\n",
      "🧠 Arquitectura de la red neuronal:\n",
      "   - Capa Entrada: 480000 neuronas (input)\n",
      "   - Capa Oculta 1: 256 neuronas (relu)\n",
      "   - Capa Oculta 2: 128 neuronas (relu)\n",
      "   - Capa Oculta 3: 64 neuronas (relu)\n",
      "   - Capa Oculta 4: 32 neuronas (relu)\n",
      "   - Capa Salida: 2 neuronas (softmax)\n",
      "\n",
      "🚀 Iniciando entrenamiento...\n",
      "Epoch 1/200 - Loss: 0.6934 - Accuracy: 0.5312\n",
      "Epoch 10/200 - Loss: 0.6934 - Accuracy: 0.5000\n",
      "Epoch 20/200 - Loss: 0.6932 - Accuracy: 0.4688\n",
      "Epoch 30/200 - Loss: 0.6937 - Accuracy: 0.4375\n",
      "Epoch 40/200 - Loss: 0.6932 - Accuracy: 0.4375\n",
      "Epoch 50/200 - Loss: 0.6934 - Accuracy: 0.4375\n",
      "Epoch 60/200 - Loss: 0.6934 - Accuracy: 0.5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 101\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 Iniciando entrenamiento...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    100\u001b[0m red \u001b[38;5;241m=\u001b[39m RedNeuronal(architecture)\n\u001b[1;32m--> 101\u001b[0m \u001b[43mred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Entrenamiento completado!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Evaluación\u001b[39;00m\n",
      "File \u001b[1;32m~\\proyectosAnaconda\\ProyectoNeuronal\\scripts\\neural_network.py:87\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, X, y, epochs, learning_rate, batch_size, verbose)\u001b[0m\n\u001b[0;32m     85\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(m)\n\u001b[0;32m     86\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(indices)\n\u001b[1;32m---> 87\u001b[0m X_shuffled \u001b[38;5;241m=\u001b[39m X[indices]\n\u001b[0;32m     88\u001b[0m y_shuffled \u001b[38;5;241m=\u001b[39m y[indices]\n\u001b[0;32m     90\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf63293-7393-4c50-9c72-51418e281093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (red_neuronal)",
   "language": "python",
   "name": "red_neuronal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
